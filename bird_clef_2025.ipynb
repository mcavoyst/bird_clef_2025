{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91844,"databundleVersionId":11361821,"sourceType":"competition"},{"sourceId":15853,"sourceType":"modelInstanceVersion","modelInstanceId":2739,"modelId":319}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"BirdCLEF+ 2025 Sample Submission\nThis is a quick run through the submission process. Test data is hidden, so we can't access it before submission. In order to make a valid submission, here's what we'll do:\n\nMake sure we predict for all 206 classes in the train data\nLoad a list of test soundscapes\nProcess each soundscape\nload audio\nsplit into 5-second chunks\nrun model inference for each chunk\nsave predictions\nMake submission csv file\nSubmit\nOk, so here we go\n\n","metadata":{}},{"cell_type":"code","source":"# !pip install kaggle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T01:43:14.500164Z","iopub.execute_input":"2025-04-10T01:43:14.500628Z","iopub.status.idle":"2025-04-10T01:43:14.505352Z","shell.execute_reply.started":"2025-04-10T01:43:14.500584Z","shell.execute_reply":"2025-04-10T01:43:14.504155Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport kagglehub\n\n# Set seed\nnp.random.seed(42)\n\n# Class labels from train audio\nclass_labels = sorted(os.listdir('/kaggle/input/birdclef-2025/train_audio/'))\n\n# List of test soundscapes (only visible during submission)\ntest_soundscape_path = '/kaggle/input/birdclef-2025/test_soundscapes/'\ntest_soundscapes = [os.path.join(test_soundscape_path, afile) for afile in sorted(os.listdir(test_soundscape_path)) if afile.endswith('.ogg')]       ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-10T01:38:58.149701Z","iopub.execute_input":"2025-04-10T01:38:58.150100Z","iopub.status.idle":"2025-04-10T01:38:58.157389Z","shell.execute_reply.started":"2025-04-10T01:38:58.150062Z","shell.execute_reply":"2025-04-10T01:38:58.156408Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Download latest version\npath = kagglehub.model_download(\"google/bird-vocalization-classifier/tensorFlow2/bird-vocalization-classifier\")\n\nprint(\"Path to model files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T01:43:27.314354Z","iopub.execute_input":"2025-04-10T01:43:27.314724Z","iopub.status.idle":"2025-04-10T01:43:28.086043Z","shell.execute_reply.started":"2025-04-10T01:43:27.314695Z","shell.execute_reply":"2025-04-10T01:43:28.085125Z"}},"outputs":[{"name":"stdout","text":"Path to model files: /kaggle/input/bird-vocalization-classifier/tensorflow2/bird-vocalization-classifier/8\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"len(class_labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T01:59:55.103433Z","iopub.execute_input":"2025-04-10T01:59:55.103762Z","iopub.status.idle":"2025-04-10T01:59:55.110214Z","shell.execute_reply.started":"2025-04-10T01:59:55.103737Z","shell.execute_reply":"2025-04-10T01:59:55.109157Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"206"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"taxonomy = pd.read_csv('/kaggle/input/birdclef-2025/taxonomy.csv')\ntaxonomy.head(9)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T02:03:52.675128Z","iopub.execute_input":"2025-04-10T02:03:52.675550Z","iopub.status.idle":"2025-04-10T02:03:52.690328Z","shell.execute_reply.started":"2025-04-10T02:03:52.675509Z","shell.execute_reply":"2025-04-10T02:03:52.689175Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"  primary_label  inat_taxon_id               scientific_name  \\\n0       1139490        1139490          Ragoniella pulchella   \n1       1192948        1192948         Oxyprora surinamensis   \n2       1194042        1194042           Copiphora colombiae   \n3        126247         126247       Leptodactylus insularum   \n4       1346504        1346504  Neoconocephalus brachypterus   \n5        134933         134933        Espadarana prosoblepon   \n6        135045         135045      Andinobates opisthomelas   \n7       1462711        1462711         Cocconotus aratifrons   \n8       1462737        1462737        Docidocercus fasciatus   \n\n                    common_name class_name  \n0          Ragoniella pulchella    Insecta  \n1         Oxyprora surinamensis    Insecta  \n2           Copiphora colombiae    Insecta  \n3        Spotted Foam-nest Frog   Amphibia  \n4  Neoconocephalus brachypterus    Insecta  \n5            Emerald Glass Frog   Amphibia  \n6            Andean Poison Frog   Amphibia  \n7         Cocconotus aratifrons    Insecta  \n8        Docidocercus fasciatus    Insecta  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>primary_label</th>\n      <th>inat_taxon_id</th>\n      <th>scientific_name</th>\n      <th>common_name</th>\n      <th>class_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1139490</td>\n      <td>1139490</td>\n      <td>Ragoniella pulchella</td>\n      <td>Ragoniella pulchella</td>\n      <td>Insecta</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1192948</td>\n      <td>1192948</td>\n      <td>Oxyprora surinamensis</td>\n      <td>Oxyprora surinamensis</td>\n      <td>Insecta</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1194042</td>\n      <td>1194042</td>\n      <td>Copiphora colombiae</td>\n      <td>Copiphora colombiae</td>\n      <td>Insecta</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>126247</td>\n      <td>126247</td>\n      <td>Leptodactylus insularum</td>\n      <td>Spotted Foam-nest Frog</td>\n      <td>Amphibia</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1346504</td>\n      <td>1346504</td>\n      <td>Neoconocephalus brachypterus</td>\n      <td>Neoconocephalus brachypterus</td>\n      <td>Insecta</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>134933</td>\n      <td>134933</td>\n      <td>Espadarana prosoblepon</td>\n      <td>Emerald Glass Frog</td>\n      <td>Amphibia</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>135045</td>\n      <td>135045</td>\n      <td>Andinobates opisthomelas</td>\n      <td>Andean Poison Frog</td>\n      <td>Amphibia</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1462711</td>\n      <td>1462711</td>\n      <td>Cocconotus aratifrons</td>\n      <td>Cocconotus aratifrons</td>\n      <td>Insecta</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1462737</td>\n      <td>1462737</td>\n      <td>Docidocercus fasciatus</td>\n      <td>Docidocercus fasciatus</td>\n      <td>Insecta</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"taxonomy.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T01:58:04.844646Z","iopub.execute_input":"2025-04-10T01:58:04.845003Z","iopub.status.idle":"2025-04-10T01:58:04.855978Z","shell.execute_reply.started":"2025-04-10T01:58:04.844977Z","shell.execute_reply":"2025-04-10T01:58:04.854776Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 206 entries, 0 to 205\nData columns (total 5 columns):\n #   Column           Non-Null Count  Dtype \n---  ------           --------------  ----- \n 0   primary_label    206 non-null    object\n 1   inat_taxon_id    206 non-null    int64 \n 2   scientific_name  206 non-null    object\n 3   common_name      206 non-null    object\n 4   class_name       206 non-null    object\ndtypes: int64(1), object(4)\nmemory usage: 8.2+ KB\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"taxonomy.primary_label.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T01:59:03.576834Z","iopub.execute_input":"2025-04-10T01:59:03.577266Z","iopub.status.idle":"2025-04-10T01:59:03.583355Z","shell.execute_reply.started":"2025-04-10T01:59:03.577237Z","shell.execute_reply":"2025-04-10T01:59:03.582455Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"206"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"taxonomy.scientific_name.nunique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T01:59:21.162069Z","iopub.execute_input":"2025-04-10T01:59:21.162441Z","iopub.status.idle":"2025-04-10T01:59:21.168499Z","shell.execute_reply.started":"2025-04-10T01:59:21.162414Z","shell.execute_reply":"2025-04-10T01:59:21.167603Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"206"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"PLAN:\n\nQuestion - is there a need to sub-specify the call type i.e. distress or mating etc.\n\n- focus on one class at a time\n- Maybe use the insect and ambibians to subtract them out.\n- overlay the correct birds etc with associated backgrounds to create additional training data. \n- Pre-clean with model detecting human speach or language to remove those clips\n  - chunk audio and clean each chunk then can recombine if needed\n  - \n","metadata":{}},{"cell_type":"code","source":"test_soundscapes[:2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T02:00:57.673168Z","iopub.execute_input":"2025-04-10T02:00:57.673515Z","iopub.status.idle":"2025-04-10T02:00:57.679606Z","shell.execute_reply.started":"2025-04-10T02:00:57.673489Z","shell.execute_reply":"2025-04-10T02:00:57.678523Z"}},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport numpy as np\nimport tensorflow_hub as hub\nimport tensorflow as tf\ntf.experimental.numpy.experimental_enable_numpy_behavior()\n\n# Load the model.\nmodel = hub.load('https://www.kaggle.com/models/google/bird-vocalization-classifier/TensorFlow2/bird-vocalization-classifier/8')\n\n# Input: 5 seconds of silence as mono 32 kHz waveform samples.\nwaveform = np.zeros(5 * 32000, dtype=np.float32)\n\n# Run the model, check the output.\nmodel_outputs = model.infer_tf(waveform[np.newaxis, :])\n\n# Examine the spectrogram.\nplt.imshow(model_outputs['frontend'][0].T)\n\n# Examine various logits.\nprint(model_outputs['label'].shape)\nprint(model_outputs['genus'].shape)\nprint(model_outputs['family'].shape)\nprint(model_outputs['order'].shape)\n\n# Examine the embeddings.\nprint(model_outputs['embedding'].shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T02:00:57.814306Z","iopub.execute_input":"2025-04-10T02:00:57.814678Z","iopub.status.idle":"2025-04-10T02:01:10.151895Z","shell.execute_reply.started":"2025-04-10T02:00:57.814649Z","shell.execute_reply":"2025-04-10T02:01:10.150755Z"}},"outputs":[{"name":"stdout","text":"(1, 10932)\n(1, 2333)\n(1, 249)\n(1, 41)\n(1, 1280)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"waveform","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T01:53:07.117462Z","iopub.execute_input":"2025-04-10T01:53:07.117807Z","iopub.status.idle":"2025-04-10T01:53:07.124669Z","shell.execute_reply.started":"2025-04-10T01:53:07.117781Z","shell.execute_reply":"2025-04-10T01:53:07.123330Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"soundscape = librosa.load('/kaggle/input/birdclef-2025/train_soundscapes/H02_20230420_074000.ogg')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T02:17:04.133870Z","iopub.execute_input":"2025-04-10T02:17:04.134321Z","iopub.status.idle":"2025-04-10T02:17:04.258585Z","shell.execute_reply.started":"2025-04-10T02:17:04.134289Z","shell.execute_reply":"2025-04-10T02:17:04.257550Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"(22050,)"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"BirdCLEF+ 2025 Sample Submission\nThis is a quick run through the submission process. Test data is hidden, so we can't access it before submission. In order to make a valid submission, here's what we'll do:\n\nMake sure we predict for all 206 classes in the train data\nLoad a list of test soundscapes\nProcess each soundscape\nload audio\nsplit into 5-second chunks\nrun model inference for each chunk\nsave predictions\nMake submission csv file\nSubmit\nOk, so here we go.","metadata":{}},{"cell_type":"markdown","source":"In order to make a submission, we need to:\n\ndisable internet for this notebook (Settings --> Turn off internet)\nmake sure the notebook runs without errors and a submission file gets created\nsubmit to competition (panel on the right)\nwait for the notebook to finish (this may take a while, remember there's a 90-min time limit)\nIf all goes well, we should see our submission scores on the leaderboard.","metadata":{}},{"cell_type":"code","source":"# Open each soundscape and make predictions for 5-second segments\n# Use pandas df with 'row_id' plus class labels as columns\npredictions = pd.DataFrame(columns=['row_id'] + class_labels)\nfor soundscape in test_soundscapes:\n\n    # Load audio\n    sig, rate = librosa.load(path=soundscape, sr=None)\n\n    # Split into 5-second chunks\n    chunks = []\n    for i in range(0, len(sig), rate*5):\n        chunk = sig[i:i+rate*5]\n        chunks.append(chunk)\n        \n    # Make predictions for each chunk\n    for i, chunk in enumerate(chunks):\n        \n        # Get row id  (soundscape id + end time of 5s chunk)      \n        row_id = os.path.basename(soundscape).split('.')[0] + f'_{i * 5 + 5}'\n        \n        # Make prediction (let's use random scores for now)\n        # scores = model.predict...\n        scores = np.random.rand(len(class_labels))\n        \n        # Append to predictions as new row\n        new_row = pd.DataFrame([[row_id] + list(scores)], columns=['row_id'] + class_labels)\n        predictions = pd.concat([predictions, new_row], axis=0, ignore_index=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T23:50:45.091030Z","iopub.execute_input":"2025-04-06T23:50:45.091442Z","iopub.status.idle":"2025-04-06T23:50:50.869502Z","shell.execute_reply.started":"2025-04-06T23:50:45.091407Z","shell.execute_reply":"2025-04-06T23:50:50.867952Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-06T23:50:50.925122Z","iopub.execute_input":"2025-04-06T23:50:50.925522Z","iopub.status.idle":"2025-04-06T23:50:54.039363Z","shell.execute_reply.started":"2025-04-06T23:50:50.925489Z","shell.execute_reply":"2025-04-06T23:50:54.038357Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Open each soundscape and make predictions for 5-second segments\n# Use pandas df with 'row_id' plus class labels as columns\npredictions = pd.DataFrame(columns=['row_id'] + class_labels)\nfor soundscape in test_soundscapes:\n\n    # Load audio\n    sig, rate = librosa.load(path=soundscape, sr=None)\n\n    # Split into 5-second chunks\n    chunks = []\n    for i in range(0, len(sig), rate*5):\n        chunk = sig[i:i+rate*5]\n        chunks.append(chunk)\n        \n    # Make predictions for each chunk\n    for i, chunk in enumerate(chunks):\n        \n        # Get row id  (soundscape id + end time of 5s chunk)      \n        row_id = os.path.basename(soundscape).split('.')[0] + f'_{i * 5 + 5}'\n        \n        # Make prediction (let's use random scores for now)\n        # scores = model.predict...\n        scores = np.random.rand(len(class_labels))\n        \n        # Append to predictions as new row\n        new_row = pd.DataFrame([[row_id] + list(scores)], columns=['row_id'] + class_labels)\n        predictions = pd.concat([predictions, new_row], axis=0, ignore_index=True)\n        \n# Save prediction as csv\npredictions.to_csv('submission.csv', index=False)\npredictions.head()\n        ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save prediction as csv\npredictions.to_csv('submission.csv', index=False)\npredictions.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}